{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53c78048-8aa3-4a82-a708-23cd1c95386b",
   "metadata": {},
   "source": [
    "# lab 3.2 Part 1: Pre-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b1cbe-e74f-4fe3-9b2a-5952cc58a786",
   "metadata": {},
   "source": [
    "## 1. Implement the Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fd0054e-f7ee-4f50-a167-52b69c85c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./code')\n",
    "from encoder import Encoder\n",
    "from data import TextDataset\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110a16dd-a428-46a6-988b-1cdec8c4c216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([1, 13, 256])\n",
      "Sentence Embedding Shape: (1, 256)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Test the Encoder \n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size)\n",
    "encoder.eval()\n",
    "\n",
    "texts = [\"This is a test sentence for the encoder.\"]\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors='pt', max_length=16)\n",
    "\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = encoder(input_ids, token_type_ids, attention_mask)\n",
    "    sentence_embeddings = hidden.cpu().numpy().mean(axis=1) # shape: [num_sentences, hidden_dim]\n",
    "\n",
    "print(\"Output Shape:\", hidden.shape)\n",
    "print(\"Sentence Embedding Shape:\", sentence_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5c13bc-70b3-4201-8859-63be46139482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw_text with 109 stories\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the podcast data\n",
    "import pickle, os\n",
    "\n",
    "data_path = \"/ocean/projects/mth240012p/shared/data\"\n",
    "raw_text_path = os.path.join(data_path, \"raw_text.pkl\")\n",
    "\n",
    "with open(raw_text_path, \"rb\") as f:\n",
    "    raw_text = pickle.load(f)\n",
    "print(\"Loaded raw_text with\", len(raw_text), \"stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f478f94-86ee-4db4-a258-dccd6cd07cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweetaspie → shape: (697, 256)\n",
      "thatthingonmyarm → shape: (2073, 256)\n",
      "tildeath → shape: (2297, 256)\n",
      "indianapolis → shape: (1554, 256)\n",
      "lawsthatchokecreativity → shape: (2084, 256)\n",
      "golfclubbing → shape: (1211, 256)\n",
      "jugglingandjesus → shape: (887, 256)\n",
      "shoppinginchina → shape: (1731, 256)\n",
      "cocoonoflove → shape: (1984, 256)\n",
      "hangtime → shape: (1927, 256)\n",
      "beneaththemushroomcloud → shape: (1916, 256)\n",
      "dialogue4 → shape: (1692, 256)\n",
      "thepostmanalwayscalls → shape: (2220, 256)\n",
      "stumblinginthedark → shape: (2681, 256)\n",
      "kiksuya → shape: (1699, 256)\n",
      "haveyoumethimyet → shape: (2985, 256)\n",
      "theinterview → shape: (1079, 256)\n",
      "againstthewind → shape: (838, 256)\n",
      "tetris → shape: (1350, 256)\n",
      "canplanetearthfeedtenbillionpeoplepart2 → shape: (2532, 256)\n",
      "alternateithicatom → shape: (2174, 256)\n",
      "goldiethegoldfish → shape: (1680, 256)\n",
      "seedpotatoesofleningrad → shape: (1376, 256)\n",
      "onapproachtopluto → shape: (1357, 256)\n",
      "canplanetearthfeedtenbillionpeoplepart1 → shape: (2341, 256)\n",
      "bluehope → shape: (1941, 256)\n",
      "superheroesjustforeachother → shape: (1440, 256)\n",
      "howtodraw → shape: (1964, 256)\n",
      "myfirstdaywiththeyankees → shape: (2786, 256)\n",
      "thumbsup → shape: (3083, 256)\n",
      "avatar → shape: (1469, 256)\n",
      "mayorofthefreaks → shape: (3274, 256)\n",
      "gangstersandcookies → shape: (1547, 256)\n",
      "breakingupintheageofgoogle → shape: (3476, 256)\n",
      "forgettingfear → shape: (1240, 256)\n",
      "waitingtogo → shape: (1587, 256)\n",
      "firetestforlove → shape: (2286, 256)\n",
      "goingthelibertyway → shape: (2471, 256)\n",
      "thefreedomridersandme → shape: (1606, 256)\n",
      "exorcism → shape: (2949, 256)\n",
      "itsabox → shape: (1708, 256)\n",
      "inamoment → shape: (966, 256)\n",
      "afearstrippedbare → shape: (1763, 256)\n",
      "swimmingwithastronauts → shape: (2127, 256)\n",
      "ifthishaircouldtalk → shape: (1854, 256)\n",
      "whenmothersbullyback → shape: (1488, 256)\n",
      "vixenandtheussr → shape: (2074, 256)\n",
      "adollshouse → shape: (1656, 256)\n",
      "catfishingstrangerstofindmyself → shape: (1522, 256)\n",
      "dialogue2 → shape: (1835, 256)\n",
      "theshower → shape: (1383, 256)\n",
      "igrewupinthewestborobaptistchurch → shape: (2449, 256)\n",
      "thesurprisingthingilearnedsailingsoloaroundtheworld → shape: (2855, 256)\n",
      "odetostepfather → shape: (2675, 256)\n",
      "threemonths → shape: (2062, 256)\n",
      "theclosetthatateeverything → shape: (1928, 256)\n",
      "souls → shape: (1868, 256)\n",
      "reachingoutbetweenthebars → shape: (1490, 256)\n",
      "fromboyhoodtofatherhood → shape: (2755, 256)\n",
      "naked → shape: (3218, 256)\n",
      "treasureisland → shape: (1763, 256)\n",
      "penpal → shape: (1592, 256)\n",
      "gpsformylostidentity → shape: (1650, 256)\n",
      "adventuresinsayingyes → shape: (2309, 256)\n",
      "dialogue1 → shape: (934, 256)\n",
      "theadvancedbeginner → shape: (1624, 256)\n",
      "singlewomanseekingmanwich → shape: (1486, 256)\n",
      "dialogue5 → shape: (1765, 256)\n",
      "undertheinfluence → shape: (1641, 256)\n",
      "leavingbaghdad → shape: (1976, 256)\n",
      "thetriangleshirtwaistconnection → shape: (1448, 256)\n",
      "lifeanddeathontheoregontrail → shape: (2389, 256)\n",
      "onlyonewaytofindout → shape: (1889, 256)\n",
      "comingofageondeathrow → shape: (2212, 256)\n",
      "legacy → shape: (1893, 256)\n",
      "canadageeseandddp → shape: (2559, 256)\n",
      "cautioneating → shape: (1587, 256)\n",
      "listo → shape: (2371, 256)\n",
      "thesecrettomarriage → shape: (1486, 256)\n",
      "googlingstrangersandkentuckybluegrass → shape: (2547, 256)\n",
      "christmas1940 → shape: (1261, 256)\n",
      "birthofanation → shape: (1590, 256)\n",
      "quietfire → shape: (1905, 256)\n",
      "becomingindian → shape: (2619, 256)\n",
      "escapingfromadirediagnosis → shape: (1423, 256)\n",
      "wheretheressmoke → shape: (1839, 256)\n",
      "whyimustspeakoutaboutclimatechange → shape: (2336, 256)\n",
      "metsmagic → shape: (1477, 256)\n",
      "learninghumanityfromdogs → shape: (1484, 256)\n",
      "myfathershands → shape: (942, 256)\n",
      "thecurse → shape: (2054, 256)\n",
      "findingmyownrescuer → shape: (1498, 256)\n",
      "food → shape: (2064, 256)\n",
      "eyespy → shape: (2336, 256)\n",
      "thetiniestbouquet → shape: (964, 256)\n",
      "buck → shape: (1677, 256)\n",
      "wildwomenanddancingqueens → shape: (1218, 256)\n",
      "stagefright → shape: (2067, 256)\n",
      "afatherscover → shape: (1182, 256)\n",
      "marryamanwholoveshismother → shape: (1532, 256)\n",
      "backsideofthestorm → shape: (1964, 256)\n",
      "dialogue3 → shape: (2013, 256)\n",
      "lifereimagined → shape: (1800, 256)\n",
      "dialogue6 → shape: (1986, 256)\n",
      "mybackseatviewofagreatromance → shape: (1794, 256)\n",
      "notontheusualtour → shape: (1431, 256)\n",
      "canplanetearthfeedtenbillionpeoplepart3 → shape: (2066, 256)\n",
      "life → shape: (2209, 256)\n",
      "sloth → shape: (2403, 256)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Encoder story with tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size)\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "encoder_outputs = {}\n",
    "\n",
    "for story_name in raw_text:\n",
    "    words = raw_text[story_name].data\n",
    "    inputs = tokenizer(words, padding=True, truncation=True, return_tensors='pt',max_length=64)\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    token_type_ids = inputs[\"token_type_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = encoder(input_ids, token_type_ids, attention_mask)\n",
    "\n",
    "    # Extract mean value of each sentence\n",
    "    sentence_embeddings = hidden.mean(dim=1).cpu().numpy()\n",
    "    encoder_outputs[story_name] = sentence_embeddings\n",
    "    print(f\"{story_name} → shape: {sentence_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0dfa4c18-ed86-4444-bec0-2d48a8d058df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling encoder outputs...\n",
      "Trimming\n",
      "Creating delayed features\n",
      "Delayed features are created\n",
      "Sample story: sweetaspie\n",
      "Lagged shape: (157, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Down sample and trim\n",
    "from preprocessing import downsample_word_vectors, make_delayed\n",
    "\n",
    "# Step 3.1: Downsample\n",
    "print(\"Downsampling encoder outputs...\")\n",
    "downsampled_encoder = downsample_word_vectors(\n",
    "    list(raw_text.keys()), encoder_outputs, raw_text\n",
    ")\n",
    "\n",
    "# Step 3.2: Trim with progress bar\n",
    "print(\"Trimming\")\n",
    "X_encoder_trimmed = {}\n",
    "for story in downsampled_encoder:\n",
    "    X_encoder_trimmed[story] = downsampled_encoder[story][5:-10, :]\n",
    "\n",
    "# Step 3.3: Create delayed version with progress bar\n",
    "print(\"Creating delayed features\")\n",
    "X_encoder_lagged = {}\n",
    "for story in X_encoder_trimmed:\n",
    "    X_encoder_lagged[story] = make_delayed(X_encoder_trimmed[story], delays=range(1, 5))\n",
    "print(\"Delayed features are created\")\n",
    "# Print one example\n",
    "story_example = list(X_encoder_lagged.keys())[0]\n",
    "print(f\"Sample story: {story_example}\")\n",
    "print(\"Lagged shape:\", X_encoder_lagged[story_example].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b646f7-f2a9-4913-9496-c9c5ba3119ff",
   "metadata": {},
   "source": [
    "# lab 3.2 Part 2: Modeling & Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
