{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd45bef-1a33-4fdb-a8e2-764e55a1f90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "from ridge_utils.DataSequence import DataSequence\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "from encoder import Encoder\n",
    "from data import TextDataset\n",
    "from train_encoder import train_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21a79ca3-eab4-4271-98f4-fadb3c586e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 109 podcast stories\n",
      "Pretrained encoder saved as pretrained_encoder.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the podcast text data\n",
    "data_path = \"/ocean/projects/mth240012p/shared/data\"\n",
    "raw_text_path = os.path.join(data_path, \"raw_text.pkl\")\n",
    "\n",
    "with open(raw_text_path, \"rb\") as f:\n",
    "    raw_text = pickle.load(f)\n",
    "\n",
    "print(f\"Loaded {len(raw_text)} podcast stories\")\n",
    "\n",
    "# Flatten all the words from all stories into a single list\n",
    "all_sentences = []\n",
    "for story in raw_text.values():\n",
    "    all_sentences.extend(story.data)\n",
    "\n",
    "# Tokenizer & Dataset\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "dataset = TextDataset(all_sentences, tokenizer, max_len=32)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Create encoder model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "encoder = Encoder(vocab_size=tokenizer.vocab_size)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "# Train the model using masked language modeling\n",
    "train_bert(\n",
    "    model=encoder,\n",
    "    dataloader=dataloader,\n",
    "    tokenizer=tokenizer,\n",
    "    epochs=20, # we can change this \n",
    "    lr=5e-4, # same as well \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Save pretrained encoder weights\n",
    "torch.save(encoder.state_dict(), \"pretrained_encoder.pt\")\n",
    "print(\"Pretrained encoder saved as pretrained_encoder.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "env_214"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
